# llama-runner

Compatible with Llama3.1 8B Instruct model

Step 1: Get the model files containing weights and tokens.
https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/tree/main/original

Step 2: Execute the code in Python3

If you are using MAC with MPS, select “Use MPS” in loading screen to utilize GPU acceleration.


### Buttons:
Play -> start the auto generation of texts and tokens.
Tokenize -> convert text to tokens
Step In -> show word choices for next token in a new window
Count for Step In -> max number of word choices to show for Step In


### Demos:
1. Pre-populating Responses Attack to Bypass Llama censorship.
Details: https://medium.com/@ksiiitm/red-teaming-llama-3-1-b7b3417c7ece
